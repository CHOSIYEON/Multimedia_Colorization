{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "attention Unet Colorizatioin.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CHOSIYEON/Multimedia_Colorization/blob/main/attention_Unet_Colorizatioin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3taJpW8YSMfA"
      },
      "source": [
        "# Get Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75_biZViSQS_"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuHRHQhGSYiE"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "import tqdm\n",
        "\n",
        "file_name = \"Multimedia_dataset.zip\"\n",
        "zip_path = os.path.join('/content/drive/MyDrive/Multimedia_dataset.zip')\n",
        "\n",
        "!cp \"{zip_path}\" .\n",
        "!unzip -q \"{file_name}\"\n",
        "!rm \"{file_name}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4_wKvXNExQx"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "import tqdm\n",
        "\n",
        "file_name = \"colorization_test_dataset.zip\"\n",
        "zip_path = os.path.join('/content/drive/MyDrive/colorization_test_dataset.zip')\n",
        "\n",
        "!cp \"{zip_path}\" .\n",
        "!unzip -q \"{file_name}\"\n",
        "!rm \"{file_name}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhrgzguZSisl"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_root = './Multimedia_dataset/train'\n",
        "val_root = './Multimedia_dataset/validation'\n",
        "\n",
        "train_examples = os.listdir(train_root)\n",
        "val_examples = os.listdir(val_root)\n",
        "\n",
        "print(len(train_examples)) #4500\n",
        "print(len(val_examples)) # 500\n",
        "\n",
        "# image read\n",
        "img = plt.imread(train_root + '/' + train_examples[1])\n",
        "# image show\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HidhQqvYS2SR"
      },
      "source": [
        "# Color-hint Transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2g_HC2YS5KF"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms\n",
        "\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "class ColorHintTransform(object):\n",
        "  def __init__(self, size=256, mode=\"training\"):\n",
        "    super(ColorHintTransform, self).__init__()\n",
        "    self.size = size\n",
        "    self.mode = mode\n",
        "    self.transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "  def bgr_to_lab(self, img):\n",
        "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
        "    l, ab = lab[:, :, 0], lab[:, :, 1:]\n",
        "    return l, ab\n",
        "\n",
        "  def hint_mask(self, bgr, threshold=[0.95, 0.97, 0.99]):\n",
        "    h, w, c = bgr.shape\n",
        "    mask_threshold = random.choice(threshold)\n",
        "    mask = np.random.random([h, w, 1]) > mask_threshold\n",
        "    return mask\n",
        "\n",
        "  def img_to_mask(self, mask_img):\n",
        "    mask = mask_img[:, :, 0, np.newaxis] >= 255\n",
        "    return mask\n",
        "\n",
        "  def __call__(self, img, mask_img=None):\n",
        "    threshold = [0.95, 0.97, 0.99]\n",
        "    if (self.mode == \"training\") | (self.mode == \"validation\"):\n",
        "      image = cv2.resize(img, (self.size, self.size))\n",
        "      mask = self.hint_mask(image, threshold)\n",
        "\n",
        "      hint_image = image * mask\n",
        "\n",
        "      l, ab = self.bgr_to_lab(image)\n",
        "      l_hint, ab_hint = self.bgr_to_lab(hint_image)\n",
        "\n",
        "      return self.transform(l), self.transform(ab), self.transform(ab_hint)\n",
        "\n",
        "    elif self.mode == \"testing\":\n",
        "      image = cv2.resize(img, (self.size, self.size))\n",
        "      hint_image = image * self.img_to_mask(mask_img)\n",
        "\n",
        "      l, _ = self.bgr_to_lab(image)\n",
        "      _, ab_hint = self.bgr_to_lab(hint_image)\n",
        "\n",
        "      return self.transform(l), self.transform(ab_hint)\n",
        "\n",
        "    else:\n",
        "      return NotImplementedError"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR-xD0pAS-dq"
      },
      "source": [
        "# Dataloader for Colorization Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3FKb2qsTBvS"
      },
      "source": [
        "import torch\n",
        "import torch.utils.data  as data\n",
        "import os\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "class ColorHintDataset(data.Dataset):\n",
        "  def __init__(self, root_path, size):\n",
        "    super(ColorHintDataset, self).__init__()\n",
        "\n",
        "    self.root_path = root_path\n",
        "    self.size = size\n",
        "    self.transforms = None\n",
        "    self.examples = None\n",
        "    self.hint = None\n",
        "    self.mask = None\n",
        "\n",
        "  def set_mode(self, mode):\n",
        "    self.mode = mode\n",
        "    self.transforms = ColorHintTransform(self.size, mode)\n",
        "    if mode == \"training\":\n",
        "      train_dir = os.path.join(self.root_path, \"train\")\n",
        "      self.examples = [os.path.join(self.root_path, \"train\", dirs) for dirs in os.listdir(train_dir)]\n",
        "    elif mode == \"validation\":\n",
        "      val_dir = os.path.join(self.root_path, \"validation\")\n",
        "      self.examples = [os.path.join(self.root_path, \"validation\", dirs) for dirs in os.listdir(val_dir)]\n",
        "    elif mode == \"testing\":\n",
        "      hint_dir = os.path.join(self.root_path, \"hint\")\n",
        "      mask_dir = os.path.join(self.root_path, \"mask\")\n",
        "      self.hint = [os.path.join(self.root_path, \"hint\", dirs) for dirs in os.listdir(hint_dir)]\n",
        "      self.mask = [os.path.join(self.root_path, \"mask\", dirs) for dirs in os.listdir(mask_dir)]\n",
        "    else:\n",
        "      raise NotImplementedError\n",
        "\n",
        "  def __len__(self):\n",
        "    if self.mode != \"testing\":\n",
        "      return len(self.examples)\n",
        "    else:\n",
        "      return len(self.hint)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    if self.mode == \"testing\":\n",
        "      hint_file_name = self.hint[idx]\n",
        "      mask_file_name = self.mask[idx]\n",
        "      hint_img = cv2.imread(hint_file_name)\n",
        "      mask_img = cv2.imread(mask_file_name)\n",
        "\n",
        "      input_l, input_hint = self.transforms(hint_img, mask_img)\n",
        "      sample = {\"l\": input_l, \"hint\": input_hint,\n",
        "                \"file_name\": \"image_%06d.png\" % int(os.path.basename(hint_file_name).split('.')[0])}\n",
        "    else:\n",
        "      file_name = self.examples[idx]\n",
        "      img = cv2.imread(file_name)\n",
        "      l, ab, hint = self.transforms(img)\n",
        "      sample = {\"l\": l, \"ab\": ab, \"hint\": hint}\n",
        "\n",
        "    return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NK7q41si_5J"
      },
      "source": [
        "print(torch.cuda.is_available())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZT10xlc9TFjk"
      },
      "source": [
        "# Example for Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWiEeaWlTI6a"
      },
      "source": [
        "import torch\n",
        "import torch.utils.data  as data\n",
        "import os\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "import tqdm\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from torchvision.transforms import Compose, ToTensor, ToPILImage\n",
        "\n",
        "def tensor2im(input_image, imtype=np.uint8):\n",
        "  if isinstance(input_image, torch.Tensor):\n",
        "      image_tensor = input_image.data\n",
        "  else:\n",
        "      return input_image\n",
        "  image_numpy = image_tensor[0].cpu().float().numpy()\n",
        "  if image_numpy.shape[0] == 1:\n",
        "      image_numpy = np.tile(image_numpy, (3, 1, 1))\n",
        "  image_numpy = np.clip((np.transpose(image_numpy, (1, 2, 0)) ),0, 1) * 255.0\n",
        "  return image_numpy.astype(imtype)\n",
        "\n",
        "# Change to your data root directory\n",
        "root_path = \"/content/Multimedia_dataset/\"\n",
        "test_path = \"/content/colorization_test_dataset/\"\n",
        "# Depend on runtime setting\n",
        "use_cuda = True\n",
        "\n",
        "train_dataset = ColorHintDataset(root_path, 128)\n",
        "train_dataset.set_mode(\"training\")\n",
        "train_dataloader = data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "val_dataset = ColorHintDataset(root_path, 128)\n",
        "val_dataset.set_mode(\"validation\")\n",
        "val_dataloader = data.DataLoader(val_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "test_dataset = ColorHintDataset(test_path, 128)\n",
        "test_dataset.set_mode(\"testing\")\n",
        "test_dataloader = data.DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "for i, data in enumerate(tqdm.tqdm(train_dataloader)):\n",
        "  if use_cuda:\n",
        "    l = data[\"l\"].to('cuda')\n",
        "    ab = data[\"ab\"].to('cuda')\n",
        "    hint = data[\"hint\"].to('cuda')\n",
        "  \n",
        "  gt_image = torch.cat((l, ab), dim=1)\n",
        "  hint_image = torch.cat((l, hint), dim=1)\n",
        "\n",
        "  gt_np = tensor2im(gt_image)\n",
        "  hint_np = tensor2im(hint_image)\n",
        "\n",
        "  gt_bgr = cv2.cvtColor(gt_np, cv2.COLOR_LAB2BGR)\n",
        "  hint_bgr = cv2.cvtColor(hint_np, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "  '''cv2_imshow(gt_bgr)\n",
        "  cv2_imshow(hint_bgr)'''\n",
        "\n",
        "\n",
        "for i, data in enumerate(tqdm.tqdm(val_dataloader)):\n",
        "  if use_cuda:\n",
        "    l = data[\"l\"].to('cuda')\n",
        "    ab = data[\"ab\"].to('cuda')\n",
        "    hint = data[\"hint\"].to('cuda')\n",
        "  \n",
        "  gt_image = torch.cat((l, ab), dim=1)\n",
        "  hint_image = torch.cat((l, hint), dim=1)\n",
        "\n",
        "  gt_np = tensor2im(gt_image)\n",
        "  hint_np = tensor2im(hint_image)\n",
        "\n",
        "  gt_bgr = cv2.cvtColor(gt_np, cv2.COLOR_LAB2BGR)\n",
        "  hint_bgr = cv2.cvtColor(hint_np, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "  '''cv2_imshow(gt_bgr)\n",
        "  cv2_imshow(hint_bgr)'''\n",
        "\n",
        "\n",
        "for i, data in enumerate(tqdm.tqdm(test_dataloader)):\n",
        "  if use_cuda:\n",
        "    l = data[\"l\"].to('cuda')\n",
        "    hint = data[\"hint\"].to('cuda')\n",
        "  \n",
        "  hint_image = torch.cat((l, hint), dim=1)\n",
        "\n",
        "  hint_np = tensor2im(hint_image)\n",
        "\n",
        "  hint_bgr = cv2.cvtColor(hint_np, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "  # cv2_imshow(hint_bgr)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuEKjx-kTso3"
      },
      "source": [
        "# Network Construction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOvdExtfizrW"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import init\n",
        "\n",
        "class up_conv(nn.Module):\n",
        "    def __init__(self,ch_in,ch_out):\n",
        "        super(up_conv,self).__init__()\n",
        "        self.up = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(ch_in,ch_out,kernel_size=3,stride=1,padding=1,bias=True),\n",
        "\t\t    nn.BatchNorm2d(ch_out),\n",
        "\t\t\tnn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.up(x)\n",
        "        return x\n",
        "\n",
        "class Recurrent_block(nn.Module):\n",
        "    def __init__(self,ch_out,t=2):\n",
        "        super(Recurrent_block,self).__init__()\n",
        "        self.t = t\n",
        "        self.ch_out = ch_out\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(ch_out,ch_out,kernel_size=3,stride=1,padding=1,bias=True),\n",
        "\t\t    nn.BatchNorm2d(ch_out),\n",
        "\t\t\tnn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        for i in range(self.t):\n",
        "\n",
        "            if i==0:\n",
        "                x1 = self.conv(x)\n",
        "            \n",
        "            x1 = self.conv(x+x1)\n",
        "        return x1\n",
        "\n",
        "class RRCNN_block(nn.Module):\n",
        "    def __init__(self,ch_in,ch_out,t=2):\n",
        "        super(RRCNN_block,self).__init__()\n",
        "        self.RCNN = nn.Sequential(\n",
        "            Recurrent_block(ch_out,t=t),\n",
        "            Recurrent_block(ch_out,t=t)\n",
        "        )\n",
        "        self.Conv_1x1 = nn.Conv2d(ch_in,ch_out,kernel_size=1,stride=1,padding=0)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.Conv_1x1(x)\n",
        "        x1 = self.RCNN(x)\n",
        "        return x+x1\n",
        "\n",
        "class Attention_block(nn.Module):\n",
        "    def __init__(self,F_g,F_l,F_int):\n",
        "        super(Attention_block,self).__init__()\n",
        "        self.W_g = nn.Sequential(\n",
        "            nn.Conv2d(F_g, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n",
        "            nn.BatchNorm2d(F_int)\n",
        "            )\n",
        "        \n",
        "        self.W_x = nn.Sequential(\n",
        "            nn.Conv2d(F_l, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n",
        "            nn.BatchNorm2d(F_int)\n",
        "        )\n",
        "\n",
        "        self.psi = nn.Sequential(\n",
        "            nn.Conv2d(F_int, 1, kernel_size=1,stride=1,padding=0,bias=True),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        \n",
        "    def forward(self,g,x):\n",
        "        g1 = self.W_g(g)\n",
        "        x1 = self.W_x(x)\n",
        "        psi = self.relu(g1+x1)\n",
        "        psi = self.psi(psi)\n",
        "\n",
        "        return x*psi\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self,img_ch=3,output_ch=2,t=2):\n",
        "        super(UNet,self).__init__()\n",
        "        \n",
        "        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "        self.Upsample = nn.Upsample(scale_factor=2)\n",
        "\n",
        "        self.RRCNN1 = RRCNN_block(ch_in=img_ch,ch_out=64,t=t)\n",
        "\n",
        "        self.RRCNN2 = RRCNN_block(ch_in=64,ch_out=128,t=t)\n",
        "        \n",
        "        self.RRCNN3 = RRCNN_block(ch_in=128,ch_out=256,t=t)\n",
        "        \n",
        "        self.RRCNN4 = RRCNN_block(ch_in=256,ch_out=512,t=t)\n",
        "        \n",
        "        self.RRCNN5 = RRCNN_block(ch_in=512,ch_out=1024,t=t)\n",
        "        \n",
        "\n",
        "        self.Up5 = up_conv(ch_in=1024,ch_out=512)\n",
        "        self.Att5 = Attention_block(F_g=512,F_l=512,F_int=256)\n",
        "        self.Up_RRCNN5 = RRCNN_block(ch_in=1024, ch_out=512,t=t)\n",
        "        \n",
        "        self.Up4 = up_conv(ch_in=512,ch_out=256)\n",
        "        self.Att4 = Attention_block(F_g=256,F_l=256,F_int=128)\n",
        "        self.Up_RRCNN4 = RRCNN_block(ch_in=512, ch_out=256,t=t)\n",
        "        \n",
        "        self.Up3 = up_conv(ch_in=256,ch_out=128)\n",
        "        self.Att3 = Attention_block(F_g=128,F_l=128,F_int=64)\n",
        "        self.Up_RRCNN3 = RRCNN_block(ch_in=256, ch_out=128,t=t)\n",
        "        \n",
        "        self.Up2 = up_conv(ch_in=128,ch_out=64)\n",
        "        self.Att2 = Attention_block(F_g=64,F_l=64,F_int=32)\n",
        "        self.Up_RRCNN2 = RRCNN_block(ch_in=128, ch_out=64,t=t)\n",
        "\n",
        "        self.Conv_1x1 = nn.Conv2d(64,output_ch,kernel_size=1,stride=1,padding=0)\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        # encoding path\n",
        "        x1 = self.RRCNN1(x)\n",
        "\n",
        "        x2 = self.Maxpool(x1)\n",
        "        x2 = self.RRCNN2(x2)\n",
        "        \n",
        "        x3 = self.Maxpool(x2)\n",
        "        x3 = self.RRCNN3(x3)\n",
        "\n",
        "        x4 = self.Maxpool(x3)\n",
        "        x4 = self.RRCNN4(x4)\n",
        "\n",
        "        x5 = self.Maxpool(x4)\n",
        "        x5 = self.RRCNN5(x5)\n",
        "\n",
        "        # decoding + concat path\n",
        "        d5 = self.Up5(x5)\n",
        "        x4 = self.Att5(g=d5,x=x4)\n",
        "        d5 = torch.cat((x4,d5),dim=1)\n",
        "        d5 = self.Up_RRCNN5(d5)\n",
        "        \n",
        "        d4 = self.Up4(d5)\n",
        "        x3 = self.Att4(g=d4,x=x3)\n",
        "        d4 = torch.cat((x3,d4),dim=1)\n",
        "        d4 = self.Up_RRCNN4(d4)\n",
        "\n",
        "        d3 = self.Up3(d4)\n",
        "        x2 = self.Att3(g=d3,x=x2)\n",
        "        d3 = torch.cat((x2,d3),dim=1)\n",
        "        d3 = self.Up_RRCNN3(d3)\n",
        "\n",
        "        d2 = self.Up2(d3)\n",
        "        x1 = self.Att2(g=d2,x=x1)\n",
        "        d2 = torch.cat((x1,d2),dim=1)\n",
        "        d2 = self.Up_RRCNN2(d2)\n",
        "\n",
        "        d1 = self.Conv_1x1(d2)\n",
        "\n",
        "        return d1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkEqaeC7dNc7"
      },
      "source": [
        "# Network Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwt6MZc_dP7N"
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print('train dataset length: ', len(train_dataloader))\n",
        "print('validation dataset length: ', len(val_dataloader))\n",
        "\n",
        "# 1. Network Setting\n",
        "net = UNet().cuda()\n",
        "\n",
        "# 2. Loss ans Optimizer setting\n",
        "import torch.optim as optim\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters() , lr= 0.001)\n",
        "\n",
        "# 3. 기타 변수들\n",
        "train_info = []\n",
        "val_info = []\n",
        "object_epoch = 30\n",
        "\n",
        "save_path = './ColorizationNetwork'\n",
        "os.makedirs(save_path, exist_ok= True)\n",
        "output_path = os.path.join(save_path, 'colorization_model.tar')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUhnWEHmi1Pt"
      },
      "source": [
        "from skimage.measure.simple_metrics import compare_psnr\n",
        "\n",
        "def batch_PSNR(img, imclean, data_range):\n",
        "    Img = img.data.cpu().numpy().astype(np.float32)\n",
        "    Iclean = imclean.data.cpu().numpy().astype(np.float32)\n",
        "    PSNR = 0\n",
        "    for i in range(Img.shape[0]):\n",
        "        PSNR += compare_psnr(Iclean[i, :, :, :], Img[i, :, :, :], data_range=data_range)\n",
        "    return (PSNR/Img.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvB-qB--d274"
      },
      "source": [
        "import tqdm \n",
        "\n",
        "def train_1epoch(net, dataloader):\n",
        "  total_loss = 0 # 1 epoch loss\n",
        "  iteration = 1 # iteration number\n",
        "\n",
        "  net.train() # training mode\n",
        "  psnr_train = []\n",
        "\n",
        "  for data in tqdm.auto.tqdm(dataloader):\n",
        "    # 1. 데이터 준비\n",
        "    l = data['l']\n",
        "    ab = data['ab']\n",
        "    hint = data['hint']\n",
        "\n",
        "    # use GPU\n",
        "    if use_cuda: \n",
        "      l = data['l'].to('cuda')\n",
        "      ab = data['ab'].to('cuda')\n",
        "      hint = data['hint'].to('cuda')\n",
        "\n",
        "    gt_image = torch.cat((l, ab), dim=1)\n",
        "    hint_image = torch.cat((l, hint), dim=1)\n",
        "\n",
        "    # 2. gradient 초기화\n",
        "    optimizer.zero_grad() # gradient zero\n",
        "\n",
        "    # 3. 네트워크 결과 얻기 (Forward)\n",
        "    output = net(hint_image)\n",
        "\n",
        "    # 4. loss 얻기\n",
        "    loss = criterion(output, ab)\n",
        "\n",
        "    # 5. gradient 계산\n",
        "    loss.backward()\n",
        "\n",
        "    # 6. gradient 적용\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.detach() # detach -> 계산 그래프의 분리, detach 그래디언트 계산함\n",
        "    iteration += 1\n",
        "\n",
        "    # psnr\n",
        "    output_image = torch.cat((l, output), dim= 1)\n",
        "    psnr = batch_PSNR(gt_image, output_image, 1.)\n",
        "    psnr_train.append(psnr)\n",
        "\n",
        "\n",
        "  mean_psnr = np.mean(psnr_train)\n",
        "  total_loss /= iteration\n",
        "\n",
        "  return mean_psnr, total_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ly-78jOHmIz"
      },
      "source": [
        "def validation_1epoch(net, dataloader):\n",
        "  total_loss = 0 # 1 epoch loss\n",
        "  iteration = 1 # iteration number\n",
        "\n",
        "# validation 을 위한 코드 구조\n",
        " # -----------------------------------------------------------------------------\n",
        "  net.eval() # validation mode\n",
        "  psnr_val = []\n",
        "\n",
        "  for data in tqdm.auto.tqdm(dataloader):\n",
        "    # 1. 데이터 준비\n",
        "    l = data['l']\n",
        "    ab = data['ab']\n",
        "    hint = data['hint']\n",
        "\n",
        "    # use GPU\n",
        "    if use_cuda: \n",
        "      l = data['l'].to('cuda')\n",
        "      ab = data['ab'].to('cuda')\n",
        "      hint = data['hint'].to('cuda')\n",
        "\n",
        "    gt_image = torch.cat((l, ab), dim=1)\n",
        "    hint_image = torch.cat((l, hint), dim=1)\n",
        "\n",
        "    # 3. 네트워크 결과 얻기 (Forward)\n",
        "    output = net(hint_image)\n",
        "\n",
        "    # 4. loss 얻기\n",
        "    loss = criterion(output, ab)\n",
        "\n",
        "    # psnr\n",
        "    output_image = torch.cat((l, output), dim= 1)\n",
        "    psnr = batch_PSNR(gt_image, output_image, 1.)\n",
        "    psnr_val.append(psnr)\n",
        "\n",
        " # -----------------------------------------------------------------------------\n",
        "\n",
        "    # detach(): Tensor 기울기 계산 그래프에서 제거\n",
        "    total_loss += loss.detach() # detach -> 계산 그래프의 분리, detach 그래디언트 계산함\n",
        "    iteration += 1\n",
        "  mean_psnr = np.mean(psnr_val)\n",
        "  total_loss /= iteration\n",
        "\n",
        "  return mean_psnr, total_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2b4BhwsHrjL"
      },
      "source": [
        "best_psnr = 0\n",
        "\n",
        "for epoch in range(object_epoch):\n",
        "  train_psnr , train_loss = train_1epoch(net, train_dataloader)\n",
        "  print('[Training] Epoch {}: PSNR: {}, loss: {}'.format(epoch, train_psnr, train_loss))\n",
        "  train_info.append({\n",
        "      'loss': train_loss,\n",
        "      'psnr': train_psnr\n",
        "  }\n",
        "  )\n",
        "\n",
        "  '''with torch.no_grad(): # gradient 를 계산하지 않겠다 \n",
        "    val_psnr, val_loss = validation_1epoch(net, val_dataloader)\n",
        "  print('[Validation] Epoch {}: psnr: {}, loss: {}'.format(epoch, val_psnr, val_loss))\n",
        "  val_info.append({\n",
        "      'loss': val_loss,\n",
        "      'psnr': val_psnr\n",
        "  }\n",
        "  )\n",
        "\n",
        "  if best_psnr < val_psnr:\n",
        "    best_psnr = val_psnr\n",
        "    torch.save({\n",
        "      'memo': 'Colorization Model',\n",
        "      'psnr': val_psnr,\n",
        "      'loss': val_loss,\n",
        "      'model_weight': net.state_dict()\n",
        "  }, output_path)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBZj-237hI2l"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epoch_axis = np.arange(0, object_epoch)\n",
        "plt.title('PSNR')\n",
        "'''plt.plot(epoch_axis, [info['psnr'] for info in train_info], epoch_axis, [info['psnr'] for info in val_info], 'r-')\n",
        "plt.legend(['Train', 'Validation'])'''\n",
        "plt.plot(epoch_axis, [info['psnr'] for info in train_info], 'r-')\n",
        "plt.legend(['Train'])\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "plt.figure()\n",
        "plt.title('Loss')\n",
        "'''plt.plot(epoch_axis, [info['loss'] for info in train_info], epoch_axis, [info['loss'] for info in val_info], 'r-')\n",
        "plt.legend(['Train', 'Validation'])'''\n",
        "plt.plot(epoch_axis, [info['loss'] for info in train_info],'r-')\n",
        "plt.legend(['Train'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWcIZafQpH7F"
      },
      "source": [
        "# Model Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww_Eo8t8pQ_O"
      },
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "model_path = os.path.join(save_path, 'colorization_model.tar')\n",
        "state_dict = torch.load(model_path)\n",
        "\n",
        "print(state_dict['memo'])\n",
        "print(state_dict.keys())\n",
        "print(state_dict['loss'])\n",
        "\n",
        "net = UNet().cuda()\n",
        "net.load_state_dict(state_dict['model_weight'], strict= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "by50bkOVsKd1"
      },
      "source": [
        "for i, data in enumerate(tqdm.tqdm(train_dataloader)):\n",
        "  if use_cuda:\n",
        "    l = data[\"l\"].to('cuda')\n",
        "    ab = data[\"ab\"].to('cuda')\n",
        "    hint = data[\"hint\"].to('cuda')\n",
        "      \n",
        "  gt_image = torch.cat((l, ab), dim=1)\n",
        "  hint_image = torch.cat((l, hint), dim=1)\n",
        "  output_image = net(hint_image)\n",
        "  output_image = torch.cat((l,output_image),dim=1)\n",
        "\n",
        "  gt_np = tensor2im(gt_image)\n",
        "  hint_np = tensor2im(hint_image)\n",
        "  output_np = tensor2im(output_image)\n",
        "\n",
        "  gt_bgr = cv2.cvtColor(gt_np, cv2.COLOR_LAB2BGR)\n",
        "  hint_bgr = cv2.cvtColor(hint_np, cv2.COLOR_LAB2BGR)\n",
        "  output_bgr = cv2.cvtColor(output_np, cv2.COLOR_LAB2BGR)\n",
        "      \n",
        "  cv2_imshow(gt_bgr)\n",
        "  cv2_imshow(hint_bgr)\n",
        "  cv2_imshow(output_bgr)\n",
        "\n",
        "  # input()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3xPY9FSfw-f"
      },
      "source": [
        "import tqdm\n",
        "\n",
        "net = UNet().cuda()\n",
        "net.load_state_dict(state_dict['model_weight'], strict= True)\n",
        "\n",
        "# os.makedirs('/content/output', exist_ok=True)\n",
        "os.makedirs('/content/drive/MyDrive/output', exist_ok=True)\n",
        "result_path = '/content/drive/MyDrive/output/'\n",
        "\n",
        "def test_1epoch(net, dataloader):\n",
        "  net.eval()\n",
        "\n",
        "  for sample in tqdm.auto.tqdm(dataloader):\n",
        "    if use_cuda:\n",
        "      l = sample[\"l\"].to('cuda')\n",
        "      hint = sample[\"hint\"].to('cuda')\n",
        "      file_name = sample[\"file_name\"]\n",
        "\n",
        "    hint_image = torch.cat((l, hint), dim=1)\n",
        "    output_image = net(hint_image)\n",
        "    output_image = torch.cat((l,output_image),dim=1)\n",
        "\n",
        "    hint_np = tensor2im(hint_image)\n",
        "    output_np = tensor2im(output_image)\n",
        "\n",
        "    hint_bgr = cv2.cvtColor(hint_np, cv2.COLOR_LAB2BGR)\n",
        "    output_bgr = cv2.cvtColor(output_np, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    cv2_imshow(hint_bgr)\n",
        "    cv2_imshow(output_bgr)\n",
        "\n",
        "    # cv2.imwrite(result_path+file_name[0], output_bgr)\n",
        "\n",
        "\n",
        "res = test_1epoch(net, test_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUX74h5luW-q"
      },
      "source": [
        "# Model Testing - Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BHMStx5Vubk"
      },
      "source": [
        "import tqdm\n",
        "\n",
        "net = UNet().cuda()\n",
        "net.load_state_dict(state_dict['model_weight'], strict= True)\n",
        "\n",
        "os.makedirs('/content/drive/MyDrive/output', exist_ok=True)\n",
        "result_path = '/content/drive/MyDrive/output/'\n",
        "\n",
        "def test_1epoch(net, dataloader):\n",
        "  net.eval()\n",
        "\n",
        "  for sample in tqdm.auto.tqdm(dataloader):\n",
        "    if use_cuda:\n",
        "      l = sample[\"l\"].to('cuda')\n",
        "      hint = sample[\"hint\"].to('cuda')\n",
        "      file_name = sample[\"file_name\"]\n",
        "\n",
        "    hint_image = torch.cat((l, hint), dim=1)\n",
        "    output_image = net(hint_image)\n",
        "    output_image = torch.cat((l,output_image),dim=1)\n",
        "\n",
        "    hint_np = tensor2im(hint_image)\n",
        "    output_np = tensor2im(output_image)\n",
        "\n",
        "    hint_bgr = cv2.cvtColor(hint_np, cv2.COLOR_LAB2BGR)\n",
        "    output_bgr = cv2.cvtColor(output_np, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    cv2_imshow(hint_bgr)\n",
        "    cv2_imshow(output_bgr)\n",
        "\n",
        "    cv2.imwrite(result_path+file_name[0], output_bgr)\n",
        "\n",
        "res = test_1epoch(net, test_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}