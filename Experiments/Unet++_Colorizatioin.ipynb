{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unet++ Colorizatioin.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CHOSIYEON/Multimedia_Colorization/blob/main/Unet%2B%2B_Colorizatioin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3taJpW8YSMfA"
      },
      "source": [
        "# Get Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75_biZViSQS_"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuHRHQhGSYiE"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "import tqdm\n",
        "\n",
        "file_name = \"Multimedia_dataset.zip\"\n",
        "zip_path = os.path.join('/content/drive/MyDrive/Multimedia_dataset.zip')\n",
        "\n",
        "!cp \"{zip_path}\" .\n",
        "!unzip -q \"{file_name}\"\n",
        "!rm \"{file_name}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4_wKvXNExQx"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "import tqdm\n",
        "\n",
        "file_name = \"colorization_test_dataset.zip\"\n",
        "zip_path = os.path.join('/content/drive/MyDrive/colorization_test_dataset.zip')\n",
        "\n",
        "!cp \"{zip_path}\" .\n",
        "!unzip -q \"{file_name}\"\n",
        "!rm \"{file_name}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhrgzguZSisl"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_root = './Multimedia_dataset/train'\n",
        "val_root = './Multimedia_dataset/validation'\n",
        "\n",
        "train_examples = os.listdir(train_root)\n",
        "val_examples = os.listdir(val_root)\n",
        "\n",
        "print(len(train_examples)) #4500\n",
        "print(len(val_examples)) # 500\n",
        "\n",
        "# image read\n",
        "img = plt.imread(train_root + '/' + train_examples[1])\n",
        "# image show\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HidhQqvYS2SR"
      },
      "source": [
        "# Color-hint Transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2g_HC2YS5KF"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms\n",
        "\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "class ColorHintTransform(object):\n",
        "  def __init__(self, size=256, mode=\"training\"):\n",
        "    super(ColorHintTransform, self).__init__()\n",
        "    self.size = size\n",
        "    self.mode = mode\n",
        "    self.transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "  def bgr_to_lab(self, img):\n",
        "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
        "    l, ab = lab[:, :, 0], lab[:, :, 1:]\n",
        "    return l, ab\n",
        "\n",
        "  def hint_mask(self, bgr, threshold=[0.95, 0.97, 0.99]):\n",
        "    h, w, c = bgr.shape\n",
        "    mask_threshold = random.choice(threshold)\n",
        "    mask = np.random.random([h, w, 1]) > mask_threshold\n",
        "    return mask\n",
        "\n",
        "  def img_to_mask(self, mask_img):\n",
        "    mask = mask_img[:, :, 0, np.newaxis] >= 255\n",
        "    return mask\n",
        "\n",
        "  def __call__(self, img, mask_img=None):\n",
        "    threshold = [0.95, 0.97, 0.99]\n",
        "    if (self.mode == \"training\") | (self.mode == \"validation\"):\n",
        "      image = cv2.resize(img, (self.size, self.size))\n",
        "      mask = self.hint_mask(image, threshold)\n",
        "\n",
        "      hint_image = image * mask\n",
        "\n",
        "      l, ab = self.bgr_to_lab(image)\n",
        "      l_hint, ab_hint = self.bgr_to_lab(hint_image)\n",
        "\n",
        "      return self.transform(l), self.transform(ab), self.transform(ab_hint)\n",
        "\n",
        "    elif self.mode == \"testing\":\n",
        "      image = cv2.resize(img, (self.size, self.size))\n",
        "      hint_image = image * self.img_to_mask(mask_img)\n",
        "\n",
        "      l, _ = self.bgr_to_lab(image)\n",
        "      _, ab_hint = self.bgr_to_lab(hint_image)\n",
        "\n",
        "      return self.transform(l), self.transform(ab_hint)\n",
        "\n",
        "    else:\n",
        "      return NotImplementedError"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR-xD0pAS-dq"
      },
      "source": [
        "# Dataloader for Colorization Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3FKb2qsTBvS"
      },
      "source": [
        "import torch\n",
        "import torch.utils.data  as data\n",
        "import os\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "class ColorHintDataset(data.Dataset):\n",
        "  def __init__(self, root_path, size):\n",
        "    super(ColorHintDataset, self).__init__()\n",
        "\n",
        "    self.root_path = root_path\n",
        "    self.size = size\n",
        "    self.transforms = None\n",
        "    self.examples = None\n",
        "    self.hint = None\n",
        "    self.mask = None\n",
        "\n",
        "  def set_mode(self, mode):\n",
        "    self.mode = mode\n",
        "    self.transforms = ColorHintTransform(self.size, mode)\n",
        "    if mode == \"training\":\n",
        "      train_dir = os.path.join(self.root_path, \"train\")\n",
        "      self.examples = [os.path.join(self.root_path, \"train\", dirs) for dirs in os.listdir(train_dir)]\n",
        "    elif mode == \"validation\":\n",
        "      val_dir = os.path.join(self.root_path, \"validation\")\n",
        "      self.examples = [os.path.join(self.root_path, \"validation\", dirs) for dirs in os.listdir(val_dir)]\n",
        "    elif mode == \"testing\":\n",
        "      hint_dir = os.path.join(self.root_path, \"hint\")\n",
        "      mask_dir = os.path.join(self.root_path, \"mask\")\n",
        "      self.hint = [os.path.join(self.root_path, \"hint\", dirs) for dirs in os.listdir(hint_dir)]\n",
        "      self.mask = [os.path.join(self.root_path, \"mask\", dirs) for dirs in os.listdir(mask_dir)]\n",
        "    else:\n",
        "      raise NotImplementedError\n",
        "\n",
        "  def __len__(self):\n",
        "    if self.mode != \"testing\":\n",
        "      return len(self.examples)\n",
        "    else:\n",
        "      return len(self.hint)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    if self.mode == \"testing\":\n",
        "      hint_file_name = self.hint[idx]\n",
        "      mask_file_name = self.mask[idx]\n",
        "      hint_img = cv2.imread(hint_file_name)\n",
        "      mask_img = cv2.imread(mask_file_name)\n",
        "\n",
        "      input_l, input_hint = self.transforms(hint_img, mask_img)\n",
        "      sample = {\"l\": input_l, \"hint\": input_hint,\n",
        "                \"file_name\": \"image_%06d.png\" % int(os.path.basename(hint_file_name).split('.')[0])}\n",
        "    else:\n",
        "      file_name = self.examples[idx]\n",
        "      img = cv2.imread(file_name)\n",
        "      l, ab, hint = self.transforms(img)\n",
        "      sample = {\"l\": l, \"ab\": ab, \"hint\": hint}\n",
        "\n",
        "    return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NK7q41si_5J"
      },
      "source": [
        "print(torch.cuda.is_available())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZT10xlc9TFjk"
      },
      "source": [
        "# Example for Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWiEeaWlTI6a"
      },
      "source": [
        "import torch\n",
        "import torch.utils.data  as data\n",
        "import os\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "import tqdm\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from torchvision.transforms import Compose, ToTensor, ToPILImage\n",
        "\n",
        "def tensor2im(input_image, imtype=np.uint8):\n",
        "  if isinstance(input_image, torch.Tensor):\n",
        "      image_tensor = input_image.data\n",
        "  else:\n",
        "      return input_image\n",
        "  image_numpy = image_tensor[0].cpu().float().numpy()\n",
        "  if image_numpy.shape[0] == 1:\n",
        "      image_numpy = np.tile(image_numpy, (3, 1, 1))\n",
        "  image_numpy = np.clip((np.transpose(image_numpy, (1, 2, 0)) ),0, 1) * 255.0\n",
        "  return image_numpy.astype(imtype)\n",
        "\n",
        "# Change to your data root directory\n",
        "root_path = \"/content/Multimedia_dataset/\"\n",
        "test_path = \"/content/colorization_test_dataset/\"\n",
        "# Depend on runtime setting\n",
        "use_cuda = True\n",
        "\n",
        "train_dataset = ColorHintDataset(root_path, 128)\n",
        "train_dataset.set_mode(\"training\")\n",
        "train_dataloader = data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "val_dataset = ColorHintDataset(root_path, 128)\n",
        "val_dataset.set_mode(\"validation\")\n",
        "val_dataloader = data.DataLoader(val_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "test_dataset = ColorHintDataset(test_path, 128)\n",
        "test_dataset.set_mode(\"testing\")\n",
        "test_dataloader = data.DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "for i, data in enumerate(tqdm.tqdm(train_dataloader)):\n",
        "  if use_cuda:\n",
        "    l = data[\"l\"].to('cuda')\n",
        "    ab = data[\"ab\"].to('cuda')\n",
        "    hint = data[\"hint\"].to('cuda')\n",
        "  \n",
        "  gt_image = torch.cat((l, ab), dim=1)\n",
        "  hint_image = torch.cat((l, hint), dim=1)\n",
        "\n",
        "  gt_np = tensor2im(gt_image)\n",
        "  hint_np = tensor2im(hint_image)\n",
        "\n",
        "  gt_bgr = cv2.cvtColor(gt_np, cv2.COLOR_LAB2BGR)\n",
        "  hint_bgr = cv2.cvtColor(hint_np, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "  '''cv2_imshow(gt_bgr)\n",
        "  cv2_imshow(hint_bgr)'''\n",
        "\n",
        "\n",
        "for i, data in enumerate(tqdm.tqdm(val_dataloader)):\n",
        "  if use_cuda:\n",
        "    l = data[\"l\"].to('cuda')\n",
        "    ab = data[\"ab\"].to('cuda')\n",
        "    hint = data[\"hint\"].to('cuda')\n",
        "  \n",
        "  gt_image = torch.cat((l, ab), dim=1)\n",
        "  hint_image = torch.cat((l, hint), dim=1)\n",
        "\n",
        "  gt_np = tensor2im(gt_image)\n",
        "  hint_np = tensor2im(hint_image)\n",
        "\n",
        "  gt_bgr = cv2.cvtColor(gt_np, cv2.COLOR_LAB2BGR)\n",
        "  hint_bgr = cv2.cvtColor(hint_np, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "  '''cv2_imshow(gt_bgr)\n",
        "  cv2_imshow(hint_bgr)'''\n",
        "\n",
        "\n",
        "for i, data in enumerate(tqdm.tqdm(test_dataloader)):\n",
        "  if use_cuda:\n",
        "    l = data[\"l\"].to('cuda')\n",
        "    hint = data[\"hint\"].to('cuda')\n",
        "  \n",
        "  hint_image = torch.cat((l, hint), dim=1)\n",
        "\n",
        "  hint_np = tensor2im(hint_image)\n",
        "\n",
        "  hint_bgr = cv2.cvtColor(hint_np, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "  # cv2_imshow(hint_bgr)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuEKjx-kTso3"
      },
      "source": [
        "# Network Construction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWE0M6rvX1iK"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class conv_block_nested(nn.Module):\n",
        "\n",
        "    def __init__(self, in_ch, mid_ch, out_ch):\n",
        "        super(conv_block_nested, self).__init__()\n",
        "        self.activation = nn.ReLU(inplace=True)\n",
        "        self.conv1 = nn.Conv2d(in_ch, mid_ch, kernel_size=3, padding=1, bias=True)\n",
        "        self.bn1 = nn.BatchNorm2d(mid_ch)\n",
        "        self.conv2 = nn.Conv2d(mid_ch, out_ch, kernel_size=3, padding=1, bias=True)\n",
        "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.activation(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        output = self.activation(x)\n",
        "\n",
        "        return output\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, in_ch=3, out_ch=2):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        n1 = 64\n",
        "        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16, n1 * 32]\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.Up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "        self.conv0_0 = conv_block_nested(in_ch, filters[0], filters[0])\n",
        "        self.conv1_0 = conv_block_nested(filters[0], filters[1], filters[1])\n",
        "        self.conv2_0 = conv_block_nested(filters[1], filters[2], filters[2])\n",
        "        self.conv3_0 = conv_block_nested(filters[2], filters[3], filters[3])\n",
        "        self.conv4_0 = conv_block_nested(filters[3], filters[4], filters[4])\n",
        "        self.conv5_0 = conv_block_nested(filters[4], filters[5], filters[5])\n",
        "\n",
        "        self.conv0_1 = conv_block_nested(filters[0] + filters[1], filters[0], filters[0])\n",
        "        self.conv1_1 = conv_block_nested(filters[1] + filters[2], filters[1], filters[1])\n",
        "        self.conv2_1 = conv_block_nested(filters[2] + filters[3], filters[2], filters[2])\n",
        "        self.conv3_1 = conv_block_nested(filters[3] + filters[4], filters[3], filters[3])\n",
        "        self.conv4_1 = conv_block_nested(filters[4] + filters[5], filters[4], filters[4])\n",
        "\n",
        "        self.conv0_2 = conv_block_nested(filters[0]*2 + filters[1], filters[0], filters[0])\n",
        "        self.conv1_2 = conv_block_nested(filters[1]*2 + filters[2], filters[1], filters[1])\n",
        "        self.conv2_2 = conv_block_nested(filters[2]*2 + filters[3], filters[2], filters[2])\n",
        "        self.conv3_2 = conv_block_nested(filters[3]*2 + filters[4], filters[3], filters[3])\n",
        "\n",
        "        self.conv0_3 = conv_block_nested(filters[0]*3 + filters[1], filters[0], filters[0])\n",
        "        self.conv1_3 = conv_block_nested(filters[1]*3 + filters[2], filters[1], filters[1])\n",
        "        self.conv2_3 = conv_block_nested(filters[2]*3 + filters[3], filters[2], filters[2])\n",
        "\n",
        "        self.conv0_4 = conv_block_nested(filters[0]*4 + filters[1], filters[0], filters[0])\n",
        "        self.conv1_4 = conv_block_nested(filters[1]*4 + filters[2], filters[1], filters[1])\n",
        "\n",
        "        self.conv0_5 = conv_block_nested(filters[0]*5 + filters[1], filters[0], filters[0])\n",
        "\n",
        "        self.final = nn.Conv2d(filters[0], out_ch, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x0_0 = self.conv0_0(x)\n",
        "        x1_0 = self.conv1_0(self.pool(x0_0))\n",
        "        x0_1 = self.conv0_1(torch.cat([x0_0, self.Up(x1_0)], 1))\n",
        "\n",
        "        x2_0 = self.conv2_0(self.pool(x1_0))\n",
        "        x1_1 = self.conv1_1(torch.cat([x1_0, self.Up(x2_0)], 1))\n",
        "        x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.Up(x1_1)], 1))\n",
        "\n",
        "        x3_0 = self.conv3_0(self.pool(x2_0))\n",
        "        x2_1 = self.conv2_1(torch.cat([x2_0, self.Up(x3_0)], 1))\n",
        "        x1_2 = self.conv1_2(torch.cat([x1_0, x1_1, self.Up(x2_1)], 1))\n",
        "        x0_3 = self.conv0_3(torch.cat([x0_0, x0_1, x0_2, self.Up(x1_2)], 1))\n",
        "\n",
        "        x4_0 = self.conv4_0(self.pool(x3_0))\n",
        "        x3_1 = self.conv3_1(torch.cat([x3_0, self.Up(x4_0)], 1))\n",
        "        x2_2 = self.conv2_2(torch.cat([x2_0, x2_1, self.Up(x3_1)], 1))\n",
        "        x1_3 = self.conv1_3(torch.cat([x1_0, x1_1, x1_2, self.Up(x2_2)], 1))\n",
        "        x0_4 = self.conv0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, self.Up(x1_3)], 1))\n",
        "\n",
        "        x5_0 = self.conv5_0(self.pool(x4_0))\n",
        "        x4_1 = self.conv4_1(torch.cat([x4_0, self.Up(x5_0)], 1))\n",
        "        x3_2 = self.conv3_2(torch.cat([x3_0, x3_1, self.Up(x4_1)], 1))\n",
        "        x2_3 = self.conv2_3(torch.cat([x2_0, x2_1, x2_2, self.Up(x3_2)], 1))\n",
        "        x1_4 = self.conv1_4(torch.cat([x1_0, x1_1, x1_2, x1_3, self.Up(x2_3)], 1))\n",
        "        x0_5 = self.conv0_5(torch.cat([x0_0, x0_1, x0_2, x0_3, x0_4, self.Up(x1_3)], 1))\n",
        "\n",
        "        output = self.final(x0_5)\n",
        "\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkEqaeC7dNc7"
      },
      "source": [
        "# Network Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwt6MZc_dP7N"
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print('train dataset length: ', len(train_dataloader))\n",
        "print('validation dataset length: ', len(val_dataloader))\n",
        "\n",
        "# 1. Network Setting\n",
        "net = UNet().cuda()\n",
        "\n",
        "# 2. Loss ans Optimizer setting\n",
        "import torch.optim as optim\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters() , lr= 0.001)\n",
        "\n",
        "# 3. 기타 변수들\n",
        "train_info = []\n",
        "val_info = []\n",
        "object_epoch = 30\n",
        "\n",
        "save_path = './ColorizationNetwork'\n",
        "os.makedirs(save_path, exist_ok= True)\n",
        "output_path = os.path.join(save_path, 'colorization_model.tar')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUhnWEHmi1Pt"
      },
      "source": [
        "from skimage.measure.simple_metrics import compare_psnr\n",
        "\n",
        "def batch_PSNR(img, imclean, data_range):\n",
        "    Img = img.data.cpu().numpy().astype(np.float32)\n",
        "    Iclean = imclean.data.cpu().numpy().astype(np.float32)\n",
        "    PSNR = 0\n",
        "    for i in range(Img.shape[0]):\n",
        "        PSNR += compare_psnr(Iclean[i, :, :, :], Img[i, :, :, :], data_range=data_range)\n",
        "    return (PSNR/Img.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvB-qB--d274"
      },
      "source": [
        "import tqdm \n",
        "\n",
        "def train_1epoch(net, dataloader):\n",
        "  total_loss = 0 # 1 epoch loss\n",
        "  iteration = 1 # iteration number\n",
        "\n",
        "  net.train() # training mode\n",
        "  psnr_train = []\n",
        "\n",
        "  for data in tqdm.auto.tqdm(dataloader):\n",
        "    # 1. 데이터 준비\n",
        "    l = data['l']\n",
        "    ab = data['ab']\n",
        "    hint = data['hint']\n",
        "\n",
        "    # use GPU\n",
        "    if use_cuda: \n",
        "      l = data['l'].to('cuda')\n",
        "      ab = data['ab'].to('cuda')\n",
        "      hint = data['hint'].to('cuda')\n",
        "\n",
        "    gt_image = torch.cat((l, ab), dim=1)\n",
        "    hint_image = torch.cat((l, hint), dim=1)\n",
        "\n",
        "    # 2. gradient 초기화\n",
        "    optimizer.zero_grad() # gradient zero\n",
        "\n",
        "    # 3. 네트워크 결과 얻기 (Forward)\n",
        "    output = net(hint_image)\n",
        "\n",
        "    # 4. loss 얻기\n",
        "    loss = criterion(output, ab)\n",
        "\n",
        "    # 5. gradient 계산\n",
        "    loss.backward()\n",
        "\n",
        "    # 6. gradient 적용\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.detach() # detach -> 계산 그래프의 분리, detach 그래디언트 계산함\n",
        "    iteration += 1\n",
        "\n",
        "    # psnr\n",
        "    output_image = torch.cat((l, output), dim= 1)\n",
        "    psnr = batch_PSNR(gt_image, output_image, 1.)\n",
        "    psnr_train.append(psnr)\n",
        "\n",
        "\n",
        "  mean_psnr = np.mean(psnr_train)\n",
        "  total_loss /= iteration\n",
        "\n",
        "  return mean_psnr, total_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ly-78jOHmIz"
      },
      "source": [
        "def validation_1epoch(net, dataloader):\n",
        "  total_loss = 0 # 1 epoch loss\n",
        "  iteration = 1 # iteration number\n",
        "\n",
        "# validation 을 위한 코드 구조\n",
        " # -----------------------------------------------------------------------------\n",
        "  net.eval() # validation mode\n",
        "  psnr_val = []\n",
        "\n",
        "  for data in tqdm.auto.tqdm(dataloader):\n",
        "    # 1. 데이터 준비\n",
        "    l = data['l']\n",
        "    ab = data['ab']\n",
        "    hint = data['hint']\n",
        "\n",
        "    # use GPU\n",
        "    if use_cuda: \n",
        "      l = data['l'].to('cuda')\n",
        "      ab = data['ab'].to('cuda')\n",
        "      hint = data['hint'].to('cuda')\n",
        "\n",
        "    gt_image = torch.cat((l, ab), dim=1)\n",
        "    hint_image = torch.cat((l, hint), dim=1)\n",
        "\n",
        "    # 3. 네트워크 결과 얻기 (Forward)\n",
        "    output = net(hint_image)\n",
        "\n",
        "    # 4. loss 얻기\n",
        "    loss = criterion(output, ab)\n",
        "\n",
        "    # psnr\n",
        "    output_image = torch.cat((l, output), dim= 1)\n",
        "    psnr = batch_PSNR(gt_image, output_image, 1.)\n",
        "    psnr_val.append(psnr)\n",
        "\n",
        " # -----------------------------------------------------------------------------\n",
        "\n",
        "    # detach(): Tensor 기울기 계산 그래프에서 제거\n",
        "    total_loss += loss.detach() # detach -> 계산 그래프의 분리, detach 그래디언트 계산함\n",
        "    iteration += 1\n",
        "  mean_psnr = np.mean(psnr_val)\n",
        "  total_loss /= iteration\n",
        "\n",
        "  return mean_psnr, total_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2b4BhwsHrjL"
      },
      "source": [
        "best_psnr = 0\n",
        "\n",
        "for epoch in range(object_epoch):\n",
        "  train_psnr , train_loss = train_1epoch(net, train_dataloader)\n",
        "  print('[Training] Epoch {}: PSNR: {}, loss: {}'.format(epoch, train_psnr, train_loss))\n",
        "  train_info.append({\n",
        "      'loss': train_loss,\n",
        "      'psnr': train_psnr\n",
        "  }\n",
        "  )\n",
        "\n",
        "  with torch.no_grad(): # gradient 를 계산하지 않겠다 \n",
        "    val_psnr, val_loss = validation_1epoch(net, val_dataloader)\n",
        "  print('[Validation] Epoch {}: psnr: {}, loss: {}'.format(epoch, val_psnr, val_loss))\n",
        "  val_info.append({\n",
        "      'loss': val_loss,\n",
        "      'psnr': val_psnr\n",
        "  }\n",
        "  )\n",
        "\n",
        "  if best_psnr < val_psnr:\n",
        "    best_psnr = val_psnr\n",
        "    torch.save({\n",
        "      'memo': 'Colorization Model',\n",
        "      'psnr': val_psnr,\n",
        "      'loss': val_loss,\n",
        "      'model_weight': net.state_dict()\n",
        "  }, output_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBZj-237hI2l"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epoch_axis = np.arange(0, object_epoch)\n",
        "plt.title('PSNR')\n",
        "plt.plot(epoch_axis, [info['psnr'] for info in train_info], epoch_axis, [info['psnr'] for info in val_info], 'r-')\n",
        "plt.legend(['Train', 'Validation'])\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "plt.figure()\n",
        "plt.title('Loss')\n",
        "plt.plot(epoch_axis, [info['loss'] for info in train_info], epoch_axis, [info['loss'] for info in val_info], 'r-')\n",
        "plt.legend(['Train', 'Validation'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWcIZafQpH7F"
      },
      "source": [
        "# Model Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww_Eo8t8pQ_O"
      },
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "model_path = os.path.join(save_path, 'colorization_model.tar')\n",
        "state_dict = torch.load(model_path)\n",
        "\n",
        "print(state_dict['memo'])\n",
        "print(state_dict.keys())\n",
        "print(state_dict['loss'])\n",
        "\n",
        "net = UNet().cuda()\n",
        "net.load_state_dict(state_dict['model_weight'], strict= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "by50bkOVsKd1"
      },
      "source": [
        "for i, data in enumerate(tqdm.tqdm(train_dataloader)):\n",
        "  if use_cuda:\n",
        "    l = data[\"l\"].to('cuda')\n",
        "    ab = data[\"ab\"].to('cuda')\n",
        "    hint = data[\"hint\"].to('cuda')\n",
        "      \n",
        "  gt_image = torch.cat((l, ab), dim=1)\n",
        "  hint_image = torch.cat((l, hint), dim=1)\n",
        "  output_image = net(hint_image)\n",
        "  output_image = torch.cat((l,output_image),dim=1)\n",
        "\n",
        "  gt_np = tensor2im(gt_image)\n",
        "  hint_np = tensor2im(hint_image)\n",
        "  output_np = tensor2im(output_image)\n",
        "\n",
        "  gt_bgr = cv2.cvtColor(gt_np, cv2.COLOR_LAB2BGR)\n",
        "  hint_bgr = cv2.cvtColor(hint_np, cv2.COLOR_LAB2BGR)\n",
        "  output_bgr = cv2.cvtColor(output_np, cv2.COLOR_LAB2BGR)\n",
        "      \n",
        "  cv2_imshow(gt_bgr)\n",
        "  cv2_imshow(hint_bgr)\n",
        "  cv2_imshow(output_bgr)\n",
        "\n",
        "  # input()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3xPY9FSfw-f"
      },
      "source": [
        "import tqdm\n",
        "\n",
        "net = UNet().cuda()\n",
        "net.load_state_dict(state_dict['model_weight'], strict= True)\n",
        "\n",
        "# os.makedirs('/content/output', exist_ok=True)\n",
        "os.makedirs('/content/drive/MyDrive/output', exist_ok=True)\n",
        "result_path = '/content/drive/MyDrive/output/'\n",
        "\n",
        "def test_1epoch(net, dataloader):\n",
        "  net.eval()\n",
        "\n",
        "  for sample in tqdm.auto.tqdm(dataloader):\n",
        "    if use_cuda:\n",
        "      l = sample[\"l\"].to('cuda')\n",
        "      hint = sample[\"hint\"].to('cuda')\n",
        "      file_name = sample[\"file_name\"]\n",
        "\n",
        "    hint_image = torch.cat((l, hint), dim=1)\n",
        "    output_image = net(hint_image)\n",
        "    output_image = torch.cat((l,output_image),dim=1)\n",
        "\n",
        "    hint_np = tensor2im(hint_image)\n",
        "    output_np = tensor2im(output_image)\n",
        "\n",
        "    hint_bgr = cv2.cvtColor(hint_np, cv2.COLOR_LAB2BGR)\n",
        "    output_bgr = cv2.cvtColor(output_np, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    cv2_imshow(hint_bgr)\n",
        "    cv2_imshow(output_bgr)\n",
        "\n",
        "    # cv2.imwrite(result_path+file_name[0], output_bgr)\n",
        "\n",
        "\n",
        "res = test_1epoch(net, test_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUX74h5luW-q"
      },
      "source": [
        "# Model Testing - Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BHMStx5Vubk"
      },
      "source": [
        "import tqdm\n",
        "\n",
        "net = UNet().cuda()\n",
        "net.load_state_dict(state_dict['model_weight'], strict= True)\n",
        "\n",
        "os.makedirs('/content/drive/MyDrive/output', exist_ok=True)\n",
        "result_path = '/content/drive/MyDrive/output/'\n",
        "\n",
        "def test_1epoch(net, dataloader):\n",
        "  net.eval()\n",
        "\n",
        "  for sample in tqdm.auto.tqdm(dataloader):\n",
        "    if use_cuda:\n",
        "      l = sample[\"l\"].to('cuda')\n",
        "      hint = sample[\"hint\"].to('cuda')\n",
        "      file_name = sample[\"file_name\"]\n",
        "\n",
        "    hint_image = torch.cat((l, hint), dim=1)\n",
        "    output_image = net(hint_image)\n",
        "    output_image = torch.cat((l,output_image),dim=1)\n",
        "\n",
        "    hint_np = tensor2im(hint_image)\n",
        "    output_np = tensor2im(output_image)\n",
        "\n",
        "    hint_bgr = cv2.cvtColor(hint_np, cv2.COLOR_LAB2BGR)\n",
        "    output_bgr = cv2.cvtColor(output_np, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    cv2_imshow(hint_bgr)\n",
        "    cv2_imshow(output_bgr)\n",
        "\n",
        "    cv2.imwrite(result_path+file_name[0], output_bgr)\n",
        "\n",
        "res = test_1epoch(net, test_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
